{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=6, suppress=True)\n",
    "\n",
    "import PIL\n",
    "import PIL.Image\n",
    "\n",
    "import pathlib\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 2 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Metric\n",
    "class RSquare(Metric):\n",
    "    \"\"\"Compute R^2 score.\n",
    "     This is also called as coefficient of determination.\n",
    "     It tells how close are data to the fitted regression line.\n",
    "     - Highest score can be 1.0 and it indicates that the predictors\n",
    "       perfectly accounts for variation in the target.\n",
    "     - Score 0.0 indicates that the predictors do not\n",
    "       account for variation in the target.\n",
    "     - It can also be negative if the model is worse.\n",
    "     Usage:\n",
    "     ```python\n",
    "     actuals = tf.constant([1, 4, 3], dtype=tf.float32)\n",
    "     preds = tf.constant([2, 4, 4], dtype=tf.float32)\n",
    "     result = tf.keras.metrics.RSquare()\n",
    "     result.update_state(actuals, preds)\n",
    "     print('R^2 score is: ', r1.result().numpy()) # 0.57142866\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name='r_square', dtype=tf.float32):\n",
    "        super(RSquare, self).__init__(name=name, dtype=dtype)\n",
    "        self.squared_sum = self.add_weight(\"squared_sum\", initializer=\"zeros\")\n",
    "        self.sum = self.add_weight(\"sum\", initializer=\"zeros\")\n",
    "        self.res = self.add_weight(\"residual\", initializer=\"zeros\")\n",
    "        self.count = self.add_weight(\"count\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred):\n",
    "        y_true = tf.convert_to_tensor(y_true, tf.float32)\n",
    "        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n",
    "        self.squared_sum.assign_add(tf.reduce_sum(y_true**2))\n",
    "        self.sum.assign_add(tf.reduce_sum(y_true))\n",
    "        self.res.assign_add(\n",
    "            tf.reduce_sum(tf.square(tf.subtract(y_true, y_pred))))\n",
    "        self.count.assign_add(tf.cast(tf.shape(y_true)[0], tf.float32))\n",
    "\n",
    "    def result(self):\n",
    "        mean = self.sum / self.count\n",
    "        total = self.squared_sum - 2 * self.sum * mean + self.count * mean**2\n",
    "        return 1 - (self.res / total)\n",
    "\n",
    "    def reset_states(self):\n",
    "        # The state of the metric will be reset at the start of each epoch.\n",
    "        self.squared_sum.assign(0.0)\n",
    "        self.sum.assign(0.0)\n",
    "        self.res.assign(0.0)\n",
    "        self.count.assign(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = ((8/2.54), (6/2.54))\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "plt.rcParams[\"mathtext.default\"] = \"rm\"\n",
    "plt.rcParams.update({'font.size': 11})\n",
    "MARKER_SIZE = 15\n",
    "cmap_m = [\"#f4a6ad\", \"#f6957e\", \"#fccfa2\", \"#8de7be\", \"#86d6f2\", \"#24a9e4\", \"#b586e0\", \"#d7f293\"]\n",
    "cmap = [\"#e94d5b\", \"#ef4d28\", \"#f9a54f\", \"#25b575\", \"#1bb1e7\", \"#1477a2\", \"#a662e5\", \"#c2f442\"]\n",
    "\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "# plt.rcParams['axes.edgecolor'] = \n",
    "plt.rcParams['axes.linewidth'] = 1\n",
    "plt.rcParams['lines.linewidth'] = 1.5\n",
    "plt.rcParams['xtick.major.width'] = 1\n",
    "plt.rcParams['xtick.minor.width'] = 1\n",
    "plt.rcParams['ytick.major.width'] = 1\n",
    "plt.rcParams['ytick.minor.width'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_HEIGHT = 1080\n",
    "IMG_WIDTH = 1080"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('./data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6374"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(data_dir.glob('*/*.jpg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_input.shape)\n",
    "print(raw_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_input.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_input = raw_input.astype(np.float32)\n",
    "raw_label = raw_label.astype(np.float32)\n",
    "test_input = test_input.astype(np.float32)\n",
    "test_label = test_label.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = int(raw_input.shape[0]*.7)\n",
    "raw_input, raw_label = shuffle(raw_input, raw_label, random_state=4574)\n",
    "train_input, train_label = raw_input[:num_train, ...], raw_label[:num_train, ...]\n",
    "val_input, val_label = raw_input[num_train:, ...], raw_label[num_train:, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_input, train_label))\n",
    "train_dataset = train_dataset.cache().shuffle(BATCH_SIZE*50).batch(BATCH_SIZE)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_input, val_label))\n",
    "val_dataset = val_dataset.cache().shuffle(BATCH_SIZE*50).batch(BATCH_SIZE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_input, test_label))\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, dropout_rate):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        self.conv1 = layers.Conv2D(self.filters, self.kernel_size,\n",
    "                                   activation='relu', kernel_initializer='he_normal', padding='same')\n",
    "        self.batch1 = layers.BatchNormalization()\n",
    "        self.drop = layers.Dropout(self.dropout_rate)\n",
    "        self.conv2 = layers.Conv2D(self.filters, self.kernel_size,\n",
    "                                   activation='relu', kernel_initializer='he_normal', padding='same')\n",
    "        self.batch2 = layers.BatchNormalization()\n",
    "        \n",
    "    def call(self, inp):\n",
    "        \n",
    "        inp = self.batch1(self.conv1(inp))\n",
    "        inp = self.drop(inp)\n",
    "        inp = self.batch2(self.conv2(inp))\n",
    "        \n",
    "        return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeconvBlock(layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, strides):\n",
    "        super(DeconvBlock, self).__init__()\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "        \n",
    "        self.deconv1 = layers.Conv2DTranspose(self.filters, self.kernel_size, strides=self.strides, padding='same')\n",
    "        \n",
    "    def call(self, inp):\n",
    "        \n",
    "        inp = self.deconv1(inp)\n",
    "        \n",
    "        return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(Model):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        self.conv_block1 = ConvBlock(32, (2, 2), 0.1)\n",
    "        self.pool1 = layers.MaxPooling2D()\n",
    "        \n",
    "        self.conv_block2 = ConvBlock(256, (2, 2), 0.2)\n",
    "        self.pool2 = layers.MaxPooling2D()\n",
    "        \n",
    "        self.conv_block3 = ConvBlock(512, (2, 2), 0.2)\n",
    "        \n",
    "        self.deconv_block1 = DeconvBlock(256, (2, 2), (2, 2))\n",
    "        self.conv_block4 = ConvBlock(256, (2, 2), 0.2)\n",
    "        \n",
    "        self.deconv_block2 = DeconvBlock(64, (2, 2), (2, 2))\n",
    "        self.padding = layers.ZeroPadding2D(((1, 0), (0, 1)))\n",
    "        self.conv_block5 = ConvBlock(128, (2, 2), 0.1)\n",
    "        \n",
    "        self.output_conv = layers.Conv2D(1, (1, 1), activation='sigmoid')\n",
    "        \n",
    "    def call(self, inp):\n",
    "        \n",
    "        conv1 = self.conv_block1(inp)\n",
    "        pooled1 = self.pool1(conv1)\n",
    "        conv2 = self.conv_block2(pooled1)\n",
    "        pooled2 = self.pool2(conv2)\n",
    "        \n",
    "        bottom = self.conv_block3(pooled2)\n",
    "        \n",
    "        deconv1 = self.padding(self.deconv_block1(bottom))\n",
    "        deconv1 = layers.concatenate([deconv1, conv2])\n",
    "        deconv1 = self.conv_block4(deconv1)\n",
    "        deconv2 = self.deconv_block2(deconv1)\n",
    "        deconv2 = layers.concatenate([deconv2, conv1])\n",
    "        deconv2 = self.conv_block5(deconv2)\n",
    "        \n",
    "        return self.output_conv(deconv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss inputs should be masked.\n",
    "loss_object = tf.keras.losses.MeanSquaredError()\n",
    "def loss_function(model, inp, tar):\n",
    "    \n",
    "    masked_real = tar * (1 - inp[..., 1:2])\n",
    "    masked_pred = model(inp) * (1 - inp[..., 1:2])\n",
    "    \n",
    "    return loss_object(masked_real, masked_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_model = UNet()\n",
    "opt = tf.optimizers.Adam(learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train(loss_function, model, opt, inp, tar):\n",
    "    with tf.GradientTape() as tape:\n",
    "        gradients = tape.gradient(loss_function(model, inp, tar), model.trainable_variables)\n",
    "        gradient_variables = zip(gradients, model.trainable_variables)\n",
    "        opt.apply_gradients(gradient_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = BEST_PATH\n",
    "\n",
    "ckpt = tf.train.Checkpoint(unet_model=unet_model,\n",
    "                           opt=opt)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.create_file_writer('tmp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prev_test_loss = 100.0\n",
    "with writer.as_default():\n",
    "    with tf.summary.record_if(True):\n",
    "        for epoch in range(TRAINING_EPOCHS):\n",
    "            for step, (inp, tar) in enumerate(train_dataset):\n",
    "                train(loss_function, unet_model, opt, inp, tar)\n",
    "                loss_values = loss_function(unet_model, inp, tar)\n",
    "                tf.summary.scalar('loss', loss_values, step=step)\n",
    "                \n",
    "                if step % DISP_STEPS == 0:\n",
    "                    test_loss = 0\n",
    "                    for step_, (inp_, tar_) in enumerate(test_dataset):\n",
    "                        test_loss += loss_function(unet_model, inp_, tar_)\n",
    "                        \n",
    "                        if step_ > DISP_STEPS:\n",
    "                            test_loss /= DISP_STEPS\n",
    "                            break\n",
    "                    if test_loss.numpy() < prev_test_loss:\n",
    "                        ckpt_save_path = ckpt_manager.save()\n",
    "                        prev_test_loss = test_loss.numpy()\n",
    "                        print('Saving checkpoint at {}'.format(ckpt_save_path))\n",
    "                    print('Epoch {} batch {} train loss: {:.4f} test loss: {:.4f}'\n",
    "                          .format(epoch, step, loss_values.numpy(), test_loss.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = -1\n",
    "if ckpt_manager.checkpoints:\n",
    "    ckpt.restore(ckpt_manager.checkpoints[i])\n",
    "    print ('Checkpoint ' + ckpt_manager.checkpoints[i][-2:] +' restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "                   loss = tf.keras.losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = unet_model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result = unet_model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_result.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_pred = []\n",
    "OUTLIER = 1\n",
    "for __ in range(5):\n",
    "    temp = []\n",
    "    for _ in range(int(pred_result.shape[1]/5)):\n",
    "        temp.append(pred_result[..., _*5:(_+1)*5, 0][..., __])\n",
    "    temp = np.stack(temp, axis=2)\n",
    "    temp.sort(axis=2)\n",
    "    avg_pred.append(temp[..., OUTLIER:-OUTLIER].mean(axis=2))\n",
    "avg_pred = np.stack(avg_pred, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masking = test_input[..., 1]\n",
    "avg_masking = masking[..., :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_pred = np.ma.array(pred_result[..., 0], mask=masking)\n",
    "masked_avg_pred = np.ma.array(avg_pred, mask=avg_masking)\n",
    "masked_label = np.ma.array(test_label[..., 0], mask=masking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    print(np.sqrt(mean_squared_error(masked_label[..., _].reshape(-1), masked_pred[..., _].reshape(-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    print(np.sqrt(mean_squared_error(masked_label[..., _].reshape(-1), masked_avg_pred[..., _].reshape(-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = RSquare()\n",
    "for _ in range(5):\n",
    "    r2.reset_states()\n",
    "    print(r2(masked_label[..., _][~masked_label[..., _].mask].data.reshape(-1),\n",
    "             masked_pred[..., _][~masked_pred[..., _].mask].data.reshape(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    r2.reset_states()\n",
    "    print(r2(masked_label[..., _][~masked_label[..., _].mask].data.reshape(-1),\n",
    "             masked_avg_pred[..., _][~masked_avg_pred[..., _].mask].data.reshape(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_label = ((MAXS[:5]-MINS[:5])*masked_label[..., :5] + MINS[:5]).reshape(-1, 1)\n",
    "plot_label = plot_label[~plot_label.mask]\n",
    "plot_pred = ((MAXS[:5]-MINS[:5])*masked_pred[..., :5] + MINS[:5]).reshape(-1, 1)\n",
    "plot_pred = plot_pred[~plot_pred.mask]\n",
    "fig = plt.figure(figsize=((8/2.54)*4, (6/2.54)*4))\n",
    "plt.scatter(plot_label, plot_pred, c=cmap[0], s=2, alpha=0.1)\n",
    "plt.show()\n",
    "\n",
    "r2 = RSquare()\n",
    "r2.reset_states()\n",
    "print(r2(plot_label, plot_pred))\n",
    "print(np.sqrt(mean_squared_error(plot_label, plot_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_label = ((MAXS[:5]-MINS[:5])*masked_label[..., :5] + MINS[:5]).reshape(-1, 1)\n",
    "plot_label = plot_label[~plot_label.mask]\n",
    "plot_avg_pred = ((MAXS[:5]-MINS[:5])*masked_avg_pred[..., :5] + MINS[:5]).reshape(-1, 1)\n",
    "plot_avg_pred = plot_avg_pred[~plot_avg_pred.mask]\n",
    "fig = plt.figure(figsize=((8/2.54)*4, (6/2.54)*4))\n",
    "plt.scatter(plot_label, plot_avg_pred, c=cmap[0], s=2, alpha=0.1)\n",
    "plt.show()\n",
    "\n",
    "r2 = RSquare()\n",
    "r2.reset_states()\n",
    "print(r2(plot_label, plot_pred))\n",
    "print(np.sqrt(mean_squared_error(plot_label, plot_avg_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t = np.arange(0, test_label.shape[1])\n",
    "for _ in range (2):\n",
    "\n",
    "        NUMBERS = np.arange(1, pred_result.shape[0])\n",
    "        np.random.shuffle(NUMBERS)\n",
    "        NUMBERS = NUMBERS[:6]\n",
    "        position = 331\n",
    "        fig = plt.figure(figsize=((8.5/2.54)*8, (6/2.54)*8))\n",
    "        \n",
    "        i=0\n",
    "        for NUMBER in NUMBERS:\n",
    "            ax = plt.subplot(position)\n",
    "            measured1 = plt.plot(x_t, test_label[NUMBER, :, i], c='k', alpha=1) #measured\n",
    "            expect1 = plt.plot(x_t, masked_pred[NUMBER, :, i], 'o', c=cmap[5], alpha=1) #estimated\n",
    "            expect1 = plt.plot(x_t, masked_avg_pred[NUMBER, :, i], 'o', c=cmap[0], alpha=1) #estimated\n",
    "            expect2 = plt.plot(x_t, pred_result[NUMBER, :, i], c=cmap[2], alpha=1) #estimated\n",
    "            ax.axis('off')\n",
    "\n",
    "            position += 1\n",
    "        plt.show()\n",
    "        _ += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_label = ((MAXS[:5]-MINS[:5])*masked_label[..., :5] + MINS[:5])\n",
    "plot_label.fill_value = np.nan\n",
    "plot_avg_pred = ((MAXS[:5]-MINS[:5])*masked_avg_pred[..., :5] + MINS[:5])\n",
    "plot_avg_pred.fill_value = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./results/UNet_%sx%s_-1.npz' % (SCREEN_SIZE, SCREEN_SIZE), 'wb')\n",
    "np.savez(f,\n",
    "         test_label = plot_label.filled(),\n",
    "         test_pred = plot_avg_pred.filled()\n",
    "        )\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p36)",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
